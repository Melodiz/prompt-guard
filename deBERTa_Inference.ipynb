{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Disable parallelism in tokenizers to avoid warnings\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline, AutoModelForSeq2SeqLM\n",
    "import torch\n",
    "import pandas as pd\n",
    "import re\n",
    "import ast\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/short_data.csv').drop(columns=['prompt_length'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the code into text using astor\n",
    "def extract_user_text(code):\n",
    "    # Parse the code into an AST\n",
    "    try:\n",
    "        tree = ast.parse(code)\n",
    "        \n",
    "        # Extract variable and class names\n",
    "        names = set()\n",
    "        for node in ast.walk(tree):\n",
    "            if isinstance(node, ast.Name):\n",
    "                names.add(node.id)\n",
    "            elif isinstance(node, ast.ClassDef):\n",
    "                names.add(node.name)\n",
    "            elif isinstance(node, ast.FunctionDef):\n",
    "                names.add(node.name)\n",
    "            elif isinstance(node, ast.Constant):\n",
    "                names.add(node.value)\n",
    "        \n",
    "        # Extract comments using regex\n",
    "        comments = re.findall(r'#.*', code)\n",
    "        \n",
    "        # Combine all extracted names and comments\n",
    "        user_text = names.union(comments)\n",
    "        \n",
    "        return ''.join([x for x in user_text if len(x) > 4]) # ommit all chars, == and so on\n",
    "    except Exception as e: \n",
    "        # print(f\"Error while extracting user text: {e}\")\n",
    "        return code.replace('\\n','. ').replace('    ', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess strings (translate Russian to English if necessary)\n",
    "russian_regex = re.compile(r'[а-яА-ЯёЁ]')\n",
    "english_regex = re.compile(r'[a-zA-Z]')\n",
    "\n",
    "translate_tokenizer = AutoTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-ru-en\")\n",
    "translate_model = AutoModelForSeq2SeqLM.from_pretrained(\"Helsinki-NLP/opus-mt-ru-en\")\n",
    "def translate_russian_to_english(text_to_translate):\n",
    "    # Split the text into words or phrases\n",
    "    if type(text_to_translate) != str:\n",
    "        try: \n",
    "            text_to_translate = ''.join(text_to_translate.split())\n",
    "        except Exception as e:\n",
    "            print(f\"Error while translating Russian to English: {e}\")\n",
    "            return text_to_translate\n",
    "    words = text_to_translate.split()\n",
    "\n",
    "    # Translate only Russian words\n",
    "    translated_words = []\n",
    "    for word in words:\n",
    "        if russian_regex.search(word):\n",
    "            # Tokenize the Russian word\n",
    "            input_tokens = translate_tokenizer.encode(word, return_tensors=\"pt\")\n",
    "            # Generate translation\n",
    "            output_tokens = translate_model.generate(input_tokens)\n",
    "            # Decode the generated tokens to get the translated word\n",
    "            translated_word = translate_tokenizer.decode(output_tokens[0], skip_special_tokens=True)\n",
    "            translated_words.append(translated_word)\n",
    "        else:\n",
    "            translated_words.append(word)\n",
    "\n",
    "    # Join the translated words back into a single string\n",
    "    translated_text = ' '.join(translated_words)\n",
    "    return translated_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "guard_tokenizer = AutoTokenizer.from_pretrained(\"ProtectAI/deberta-v3-base-prompt-injection-v2\")\n",
    "guard_model = AutoModelForSequenceClassification.from_pretrained(\"ProtectAI/deberta-v3-base-prompt-injection-v2\")\n",
    "\n",
    "classifier = pipeline(\n",
    "  \"text-classification\",\n",
    "  model=guard_model,\n",
    "  tokenizer=guard_tokenizer,\n",
    "  truncation=True,\n",
    "  max_length=512,\n",
    "  device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipe_full(prompt):\n",
    "    pormpt = extract_user_text(prompt)\n",
    "    pormpt = translate_russian_to_english(pormpt)\n",
    "    return classifier(pormpt)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "scores = []\n",
    "\n",
    "# Process all prompts in the DataFrame\n",
    "for prompt in tqdm(df['Prompt']):\n",
    "    # Extract user text from the prompt\n",
    "    extracted_text = extract_user_text(prompt)\n",
    "    \n",
    "    # Translate the extracted text from Russian to English if necessary\n",
    "    translated_text = translate_russian_to_english(extracted_text)\n",
    "    \n",
    "    # Get the prediction from the classifier model\n",
    "    prediction = classifier(translated_text)[0]\n",
    "    \n",
    "    # Append the label and score to separate lists\n",
    "    labels.append(prediction['label'])\n",
    "    scores.append(prediction['score'])\n",
    "\n",
    "# Add the labels and scores to the dataframe for all prompts\n",
    "df['Label'] = labels\n",
    "df['Score'] = scores\n",
    "\n",
    "# Save the dataframe to a CSV file\n",
    "df.to_csv('data/result_with_labels.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the dataframe to a CSV file\n",
    "df.to_csv('data/result_with_labels.csv', index=False)\n",
    "print(\"Data saved to 'data/result_with_labels.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'target' column exists in the DataFrame with true labels\n",
    "# Map the predicted labels to numerical values\n",
    "df['Predicted'] = df['Label'].map({'INJECTION': 1, 'SAFE': 0})\n",
    "# head_df = df.head(100)\n",
    "\n",
    "# Calculate accuracy\n",
    "correct_predictions = (df['Predicted'] == df['target']).sum()\n",
    "total_predictions = len(df)\n",
    "accuracy = correct_predictions / total_predictions\n",
    "\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
